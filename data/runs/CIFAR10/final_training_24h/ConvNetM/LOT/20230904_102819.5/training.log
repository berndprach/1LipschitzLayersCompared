20230904:12:28:19 Loading of the setting file...
20230904:12:28:19 Running on device cuda
20230904:12:28:19 Saving current configuration...
20230904:12:28:19 batch_size: 256
device: cuda
epochs: 132
eval_metrics:
  margin_at_50: !metric
    aggregation: 'lambda x: -((-x).quantile(0.5))'
    name: Margin
  robstacc_108: !metric
    eps: 0.4235
    name: RobustAccuracy
  robstacc_255: !metric
    eps: 1.0
    name: RobustAccuracy
  robstacc_36: !metric
    eps: 0.1411
    name: RobustAccuracy
  robstacc_72: !metric
    eps: 0.2824
    name: RobustAccuracy
  throughput: !metric
    name: Throughput
loss: !metric
  margin: 0.3993
  name: LipCrossEntropyLoss
  temperature: 0.25
lr_scheduler: !scheduler
  epochs: 132
  name: OneCycleLR
model: !model
  get_activation: !layer 'MaxMin'
  get_conv: !layer 'LOT'
  model_id: ConvNetM
  name: conv_net
  seed: 613
num_workers: 4
optimizer: !optimizer
  lr: 0.0234938619191173
  momentum: 0.9
  name: SGD
  weight_decay: 8.677492147964722e-06
trainset: !dataset
  center: true
  name: CIFAR10
  train: true
valset: !dataset
  center: true
  name: CIFAR10
  train: false

20230904:12:28:19 Done.
20230904:12:28:19 Loading objects...
20230904:12:28:21 Initializing trainer...
20230904:12:28:25 Trainset: Dataset CIFAR10
    Number of datapoints: 50000
    Root location: data/datasets
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.49139968, 0.48215841, 0.44653091], std=[1.0, 1.0, 1.0])
               RandomCrop(size=(32, 32), padding=4)
               RandomHorizontalFlip(p=0.5)
           )
20230904:12:28:25 Validation SSet: Dataset CIFAR10
    Number of datapoints: 10000
    Root location: data/datasets
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.49139968, 0.48215841, 0.44653091], std=[1.0, 1.0, 1.0])
           )
20230904:12:28:25 Loading training dataloader
20230904:12:28:25 Loading validation dataloader
20230904:12:28:25 Statistics to be computed: 
20230904:12:28:25 Metric Aggreggation Map:
{'train_loss': 'mean'
 'val_loss': 'mean'
 'train_accuracy': 'mean'
 'val_accuracy': 'mean'
 'train_robstacc_108': 'mean'
 'val_robstacc_108': 'mean'
 'train_robstacc_255': 'mean'
 'val_robstacc_255': 'mean'
 'train_robstacc_36': 'mean'
 'val_robstacc_36': 'mean'
 'train_robstacc_72': 'mean'
 'val_robstacc_72': 'mean'
 'train_throughput': 'mean'
 'val_throughput': 'mean'
 'train_margin_at_50': <function <lambda> at 0x14777dc4bf70>
 'val_margin_at_50': <function <lambda> at 0x14777c572040>
 'epoch': 'none'}
Empty DataFrame
Columns: [epoch, train_loss, val_loss, train_accuracy, val_accuracy, train_margin_at_50, val_margin_at_50, train_robstacc_108, val_robstacc_108, train_robstacc_255, val_robstacc_255, train_robstacc_36, val_robstacc_36, train_robstacc_72, val_robstacc_72, train_throughput, val_throughput]
Index: []
20230904:12:28:25 Start training...
20230904:12:38:48 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                      1    | [0.00097 | 0.2678   | 0.8687   |     0    | 0.00228  |     0    | 0.06326  | 0.01342  | 80.87    | 0.3575   | 0.8018   |     0    | 0.0124   |     0    | 0.1581   | 0.0547   |  3912   
20230904:12:49:10     2    | [0.00108 | 0.3482   | 0.8097   |     0    | 0.0078   |     0    | 0.1307   | 0.03556  | 81.13    | 0.4059   | 0.7662   |     0    | 0.0241   |     0    | 0.1851   | 0.0713   |  3930   
20230904:12:59:33     3    | [0.00127 | 0.3743   | 0.7869   |     0    | 0.01492  |     0    | 0.165    | 0.05518  |  81.1    | 0.4191   | 0.7443   |     0    | 0.0377   |     0    | 0.2375   | 0.1002   |  3902   
20230904:13:09:56     4    | [0.00153 | 0.3957   | 0.7661   |     0    | 0.02358  | 2e-05    | 0.193    | 0.07618  |  81.1    | 0.4361   | 0.7285   |     0    | 0.0512   | 0.0003   | 0.2479   | 0.1169   |  3902   
20230904:13:20:19     5    | [0.00186 | 0.4158   | 0.7454   |     0    | 0.03314  | 8e-05    | 0.2208   | 0.0927   | 81.08    | 0.4657   | 0.6951   |     0    | 0.0569   | 0.0002   | 0.2735   | 0.1382   |  3856   
20230904:13:30:42     6    | [0.00225 | 0.4356   | 0.7234   |     0    | 0.04506  | 0.00016  | 0.2403   | 0.1129   |  81.1    | 0.487    | 0.6728   |     0    | 0.074    | 0.0003   | 0.2924   | 0.1584   |  3870   
20230904:13:41:05     7    | [0.00272 | 0.4569   | 0.7018   |     0    | 0.05608  | 0.00064  | 0.2661   | 0.1322   | 81.03    | 0.4957   | 0.6633   |     0    | 0.0829   | 0.0016   | 0.3015   | 0.1665   |  3855   
20230904:13:51:28     8    | [0.00324 | 0.4721   | 0.6849   |     0    | 0.06786  | 0.00078  | 0.2845   | 0.1475   | 81.04    | 0.5191   | 0.6342   | 0.01904  | 0.1031   | 0.001    | 0.341    | 0.2057   |  3913   
20230904:14:01:52     9    | [0.00383 | 0.4855   | 0.6708   |     0    | 0.0812   | 0.00108  | 0.3003   | 0.1656   | 81.06    | 0.5109   | 0.6347   | 0.01245  | 0.1451   | 0.0052   | 0.3567   | 0.2381   |  3922   
20230904:14:12:15    10    | [0.00447 | 0.4948   | 0.6586   |     0    | 0.08968  | 0.00182  | 0.3142   | 0.1762   | 81.03    | 0.539    | 0.6129   | 0.04477  | 0.128    | 0.0028   | 0.3649   | 0.2256   |  3929   
20230904:14:12:15 Saving Checkpoint...
20230904:14:12:15 Done.
20230904:14:22:38 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                     11    | [0.00516 | 0.5118   | 0.6455   | 0.01269  | 0.1018   | 0.00246  | 0.3303   | 0.1944   |  81.1    | 0.551    | 0.5895   | 0.06537  | 0.1567   | 0.0049   | 0.3944   | 0.2589   |  3897   
20230904:14:33:01    12    | [0.00590 | 0.515    | 0.6365   | 0.01668  | 0.1085   | 0.0031   | 0.3419   | 0.2014   | 81.07    | 0.5664   | 0.5837   | 0.08194  | 0.1528   | 0.0071   | 0.4029   | 0.2581   |  3925   
20230904:14:43:24    13    | [0.00668 | 0.5219   | 0.6305   | 0.02448  | 0.1133   | 0.00364  | 0.3472   | 0.2085   | 81.06    | 0.557    | 0.5854   | 0.07677  | 0.1864   | 0.0124   | 0.4086   | 0.2852   |  3934   
20230904:14:53:46    14    | [0.00750 | 0.5296   | 0.6231   | 0.03399  | 0.1158   | 0.00376  | 0.3562   | 0.2131   | 81.14    | 0.5732   | 0.5706   | 0.08709  | 0.1652   | 0.0084   | 0.4108   | 0.2739   |  3929   
20230904:15:04:09    15    | [0.00835 | 0.5299   | 0.6223   | 0.03528  | 0.1235   | 0.0043   | 0.3608   | 0.2213   |  81.1    | 0.5833   | 0.5622   | 0.1066   | 0.1834   | 0.0089   | 0.4243   | 0.2881   |  3913   
20230904:15:14:32    16    | [0.00922 | 0.5427   | 0.6089   | 0.04869  | 0.1267   | 0.00426  | 0.3713   | 0.228    | 81.09    | 0.5849   | 0.5571   | 0.1083   | 0.1859   | 0.0113   | 0.4282   | 0.2911   |  3927   
20230904:15:24:55    17    | [0.01011 | 0.546    | 0.6057   | 0.05291  | 0.1307   | 0.00442  | 0.3785   | 0.2333   | 81.11    | 0.5899   | 0.5553   | 0.1116   | 0.1799   | 0.0071   | 0.433    | 0.2915   |  3918   
20230904:15:35:18    18    | [0.01102 | 0.5534   | 0.5991   | 0.05981  | 0.1326   | 0.00454  | 0.3819   | 0.2378   | 81.09    | 0.5422   | 0.5938   | 0.06706  | 0.1859   | 0.0084   | 0.4101   | 0.2913   |  3927   
20230904:15:45:40    19    | [0.01194 | 0.5537   | 0.5967   | 0.06162  | 0.1389   | 0.00496  | 0.3856   | 0.2427   | 81.12    | 0.5667   | 0.5807   | 0.08502  | 0.1809   | 0.0118   | 0.4118   | 0.2849   |  3928   
20230904:15:56:03    20    | [0.01285 | 0.5626   | 0.5908   | 0.07123  | 0.1432   | 0.00502  | 0.3902   | 0.2455   | 81.13    | 0.592    | 0.5528   | 0.119    | 0.1953   | 0.0147   | 0.4368   | 0.3027   |  3929   
20230904:15:56:03 Saving Checkpoint...
20230904:15:56:03 Done.
20230904:16:06:26 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                     21    | [0.01377 | 0.5668   | 0.5857   | 0.07691  | 0.1465   | 0.00552  | 0.3956   | 0.2504   |  81.1    | 0.6023   | 0.5485   | 0.1253   | 0.1866   | 0.0106   | 0.4337   | 0.2946   |  3933   
20230904:16:16:48    22    | [0.01467 | 0.5737   | 0.5779   | 0.08604  | 0.1483   | 0.00494  | 0.4024   | 0.2584   | 81.14    | 0.5844   | 0.5547   | 0.1054   | 0.1828   | 0.0177   | 0.4255   | 0.2833   |  3848   
20230904:16:27:11    23    | [0.01556 | 0.5736   | 0.5755   | 0.08935  | 0.1522   | 0.0056   | 0.4107   | 0.2633   | 81.11    | 0.5999   | 0.5474   | 0.1221   | 0.1987   | 0.0135   | 0.4449   | 0.306    |  3928   
20230904:16:37:34    24    | [0.01642 | 0.5808   | 0.5716   | 0.09347  | 0.1544   | 0.00612  | 0.4112   | 0.2656   | 81.06    | 0.6041   | 0.5433   | 0.1332   | 0.2045   | 0.0127   | 0.4482   | 0.306    |  3926   
20230904:16:47:57    25    | [0.01726 | 0.5802   | 0.5717   | 0.09284  | 0.1558   | 0.00572  | 0.4104   | 0.2661   |  81.1    | 0.6118   | 0.5257   | 0.1554   | 0.2237   | 0.0143   | 0.4679   | 0.3317   |  3908   
20230904:16:58:20    26    | [0.01806 | 0.5872   | 0.5642   | 0.1053   | 0.1587   | 0.00634  | 0.4226   | 0.2745   | 81.12    | 0.6205   | 0.5194   | 0.1576   | 0.2157   | 0.0147   | 0.4674   | 0.3268   |  3926   
20230904:17:08:42    27    | [0.01883 | 0.5867   | 0.5648   | 0.1017   | 0.1589   | 0.00612  | 0.419    | 0.2707   | 81.08    | 0.5995   | 0.5446   | 0.1267   | 0.1868   | 0.0083   | 0.4406   | 0.3002   |  3912   
20230904:17:19:06    28    | [0.01955 | 0.5921   | 0.5584   | 0.109    | 0.1647   | 0.0073   | 0.4276   | 0.278    | 81.09    | 0.5989   | 0.5385   | 0.1425   | 0.2188   | 0.0141   | 0.4573   | 0.3253   |  3929   
20230904:17:29:28    29    | [0.02022 | 0.5911   | 0.5596   | 0.1081   | 0.1673   | 0.00658  | 0.4233   | 0.2795   | 81.08    | 0.6136   | 0.5261   | 0.146    | 0.2036   | 0.0094   |  0.46    | 0.3227   |  3919   
20230904:17:39:51    30    | [0.02084 | 0.6003   | 0.5522   | 0.1196   | 0.1678   | 0.00692  | 0.4347   | 0.2832   | 81.14    | 0.5747   | 0.554    | 0.117    | 0.2243   | 0.022    | 0.449    | 0.329    |  3928   
20230904:17:39:51 Saving Checkpoint...
20230904:17:39:52 Done.
20230904:17:50:14 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                     31    | [0.02140 | 0.5954   | 0.5558   | 0.1145   | 0.1695   | 0.00662  | 0.4293   | 0.2838   |  81.1    | 0.6143   | 0.5203   | 0.164    | 0.2292   | 0.0137   | 0.4741   | 0.3363   |  3927   
20230904:18:00:37    32    | [0.02190 | 0.6012   | 0.5507   | 0.1206   | 0.172    | 0.007    | 0.4343   | 0.2876   | 81.12    | 0.6306   | 0.5112   | 0.1721   | 0.2161   | 0.0104   | 0.4802   | 0.3365   |  3926   
20230904:18:11:00    33    | [0.02234 | 0.6074   | 0.5446   | 0.129    | 0.1745   | 0.00726  | 0.4423   | 0.2913   | 81.08    | 0.6134   | 0.5149   | 0.1702   | 0.2333   | 0.0175   | 0.4809   | 0.3506   |  3927   
20230904:18:21:23    34    | [0.02271 | 0.608    | 0.5433   | 0.1266   | 0.176    | 0.00714  | 0.4416   | 0.2935   | 81.05    | 0.6289   | 0.5109   | 0.1664   | 0.2271   | 0.0191   | 0.476    | 0.337    |  3927   
20230904:18:31:46    35    | [0.02301 | 0.613    | 0.5389   | 0.1355   | 0.1786   | 0.00728  | 0.4476   | 0.2954   | 81.07    | 0.6359   | 0.5059   | 0.186    | 0.2304   | 0.0114   | 0.4904   | 0.3499   |  3921   
20230904:18:42:09    36    | [0.02324 | 0.6152   | 0.5378   | 0.1374   | 0.1814   | 0.00778  | 0.4491   | 0.2974   |  81.1    | 0.6149   | 0.5209   | 0.1652   | 0.2302   | 0.0174   | 0.4773   | 0.3404   |  3926   
20230904:18:52:31    37    | [0.02339 | 0.6156   | 0.5355   | 0.138    | 0.1834   | 0.00868  | 0.4494   | 0.3028   | 81.13    | 0.6345   | 0.5086   | 0.1851   | 0.2265   | 0.0134   | 0.4874   | 0.3424   |  3934   
20230904:19:02:53    38    | [0.02348 | 0.6169   | 0.5341   | 0.1424   | 0.1845   | 0.0078   | 0.4525   | 0.303    | 81.16    | 0.632    | 0.5095   | 0.1839   | 0.2391   | 0.0165   | 0.491    | 0.3529   |  3907   
20230904:19:13:16    39    | [0.02349 | 0.6209   | 0.5301   | 0.1465   | 0.1881   | 0.0078   | 0.4563   | 0.3063   | 81.16    | 0.6288   | 0.5059   | 0.1801   | 0.2364   | 0.0194   | 0.4854   | 0.3538   |  3928   
20230904:19:23:38    40    | [0.02348 | 0.6223   | 0.528    | 0.1514   | 0.1892   | 0.00854  | 0.4619   | 0.3086   | 81.14    | 0.6426   | 0.4935   | 0.2005   | 0.2497   | 0.014    | 0.5009   | 0.3659   |  3928   
20230904:19:23:38 Saving Checkpoint...
20230904:19:23:39 Done.
20230904:19:34:01 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                     41    | [0.02345 | 0.6219   | 0.5309   | 0.1444   | 0.1881   | 0.00852  | 0.4551   | 0.3075   |  81.1    | 0.6416   | 0.4941   | 0.2035   | 0.2489   | 0.0169   | 0.5038   | 0.3636   |  3930   
20230904:19:44:24    42    | [0.02341 | 0.6288   | 0.5234   | 0.1568   | 0.1929   | 0.00946  | 0.4658   | 0.3137   | 81.12    | 0.6586   | 0.4861   | 0.2042   | 0.2369   | 0.0146   | 0.5038   | 0.3571   |  3929   
20230904:19:54:47    43    | [0.02336 | 0.6305   | 0.5228   | 0.1586   | 0.1922   | 0.00792  | 0.4655   | 0.3152   | 81.15    | 0.6629   | 0.4827   | 0.2059   | 0.238    | 0.0146   | 0.5053   | 0.3529   |  3930   
20230904:20:05:09    44    | [0.02329 | 0.6302   | 0.5204   | 0.1592   | 0.1963   | 0.00878  | 0.4674   | 0.316    | 81.12    | 0.6559   | 0.4889   | 0.2073   | 0.239    | 0.0179   | 0.5052   | 0.3595   |  3930   
20230904:20:15:32    45    | [0.02321 | 0.6321   | 0.5187   | 0.1625   | 0.198    | 0.00906  | 0.4692   | 0.3187   | 81.11    | 0.6328   | 0.5107   | 0.1852   | 0.2294   | 0.0156   | 0.4882   | 0.3479   |  3931   
20230904:20:25:55    46    | [0.02312 | 0.6385   | 0.5141   | 0.1696   | 0.1998   | 0.0095   | 0.4752   | 0.3231   | 81.11    | 0.6577   | 0.4835   | 0.2207   | 0.2531   | 0.0156   | 0.5158   | 0.3722   |  3930   
20230904:20:36:17    47    | [0.02301 | 0.6372   | 0.5151   | 0.1673   | 0.1973   | 0.00942  | 0.4726   | 0.3188   | 81.14    | 0.6263   | 0.5099   | 0.1813   | 0.227    | 0.0126   | 0.4885   | 0.3474   |  3924   
20230904:20:46:40    48    | [0.02289 | 0.6382   | 0.5134   | 0.1704   | 0.2007   | 0.00902  | 0.4769   | 0.3253   | 81.08    | 0.6515   | 0.4895   | 0.2054   | 0.2445   | 0.0166   | 0.5044   | 0.3604   |  3932   
20230904:20:57:03    49    | [0.02276 | 0.6375   | 0.5118   | 0.1707   | 0.2025   | 0.00966  | 0.4775   | 0.327    | 81.09    | 0.6651   | 0.4804   | 0.2183   | 0.242    | 0.0157   | 0.5135   | 0.3707   |  3935   
20230904:21:07:25    50    | [0.02262 | 0.6434   | 0.5071   | 0.1776   | 0.2058   | 0.00998  | 0.4824   | 0.3305   | 81.12    | 0.6679   | 0.4772   | 0.2181   | 0.2397   | 0.014    | 0.5141   | 0.3644   |  3930   
20230904:21:07:25 Saving Checkpoint...
20230904:21:07:26 Done.
20230904:21:17:48 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                     51    | [0.02246 | 0.644    | 0.5085   | 0.1754   | 0.2049   | 0.00926  | 0.4813   | 0.3307   | 81.05    | 0.5823   | 0.5535   | 0.121    | 0.2129   | 0.0249   | 0.448    | 0.3173   |  3931   
20230904:21:28:12    52    | [0.02229 | 0.6459   | 0.5068   | 0.1786   | 0.2048   | 0.01006  | 0.4823   | 0.3313   | 81.07    | 0.6591   | 0.4774   |  0.22    | 0.2533   | 0.0169   | 0.5153   | 0.3744   |  3930   
20230904:21:38:34    53    | [0.02211 | 0.6521   | 0.5017   | 0.1856   | 0.2118   | 0.01014  | 0.4889   | 0.3371   | 81.07    | 0.6646   | 0.4809   | 0.2176   | 0.2398   | 0.0146   | 0.5122   | 0.3612   |  3927   
20230904:21:48:57    54    | [0.02192 | 0.6455   | 0.5031   | 0.184    | 0.2111   | 0.01098  | 0.4876   | 0.3357   | 81.12    | 0.6695   | 0.4778   | 0.2218   | 0.2344   | 0.0125   | 0.5166   | 0.3629   |  3929   
20230904:21:59:20    55    | [0.02171 | 0.6524   | 0.4992   | 0.1865   | 0.2119   | 0.0105   | 0.4885   | 0.338    | 81.09    | 0.6719   | 0.4671   | 0.2319   | 0.2556   | 0.0188   | 0.5225   | 0.3814   |  3928   
20230904:22:09:43    56    | [0.02149 | 0.6521   | 0.4998   | 0.1903   | 0.2118   | 0.01052  | 0.4917   | 0.3379   |  81.1    | 0.647    | 0.4905   | 0.1995   | 0.2382   | 0.0199   |   0.5    | 0.3543   |  3934   
20230904:22:20:06    57    | [0.02126 | 0.6533   | 0.4977   | 0.1908   | 0.2141   | 0.01098  | 0.493    | 0.3378   | 81.13    | 0.647    | 0.4793   | 0.2237   | 0.2751   | 0.0247   | 0.5135   | 0.3867   |  3922   
20230904:22:30:29    58    | [0.02102 | 0.6557   | 0.496    | 0.1928   | 0.2152   | 0.01106  | 0.494    | 0.3401   | 81.11    | 0.6741   | 0.4721   |  0.23    | 0.2556   | 0.0172   | 0.5237   | 0.3742   |  3931   
20230904:22:40:51    59    | [0.02077 | 0.659    | 0.4929   | 0.196    | 0.2191   | 0.01142  | 0.4974   | 0.3462   | 81.11    | 0.6597   | 0.4715   | 0.2334   | 0.274    | 0.0232   | 0.5239   | 0.3924   |  3922   
20230904:22:51:14    60    | [0.02051 | 0.6589   | 0.4914   | 0.1976   | 0.2199   | 0.01194  | 0.4986   | 0.3463   | 81.11    | 0.6786   | 0.463    | 0.2407   | 0.2541   | 0.0185   | 0.5324   | 0.375    |  3934   
20230904:22:51:14 Saving Checkpoint...
20230904:22:51:14 Done.
20230904:23:01:37 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                     61    | [0.02024 | 0.6595   | 0.4899   | 0.1984   | 0.2214   | 0.01224  | 0.4989   | 0.3475   | 81.11    | 0.6677   | 0.4744   | 0.2301   | 0.2565   | 0.0192   | 0.5211   | 0.3786   |  3927   
20230904:23:12:00    62    | [0.01996 | 0.6584   | 0.4923   | 0.1974   | 0.222    | 0.0117   | 0.4982   | 0.3483   | 81.07    | 0.6679   | 0.474    | 0.2293   | 0.2661   | 0.018    | 0.5222   | 0.3841   |  3929   
20230904:23:22:23    63    | [0.01967 | 0.6642   | 0.4866   | 0.2073   | 0.2237   | 0.01116  | 0.5064   | 0.3515   | 81.07    | 0.6912   | 0.4525   | 0.2524   | 0.2691   | 0.0181   | 0.5418   | 0.3967   |  3924   
20230904:23:32:46    64    | [0.01937 | 0.6685   | 0.4841   | 0.2099   | 0.2265   | 0.01166  | 0.5083   | 0.3544   | 81.02    | 0.6779   | 0.4586   | 0.2445   | 0.2706   | 0.021    | 0.5307   | 0.3934   |  3925   
20230904:23:43:10    65    | [0.01907 | 0.6652   | 0.4845   | 0.2075   | 0.2272   | 0.0127   | 0.5067   | 0.3554   | 81.06    | 0.6786   | 0.4585   | 0.2477   | 0.266    | 0.0233   | 0.5362   | 0.3926   |  3926   
20230904:23:53:33    66    | [0.01875 | 0.6642   | 0.4871   | 0.2063   | 0.226    | 0.01222  | 0.5053   | 0.3543   | 81.08    | 0.6886   | 0.4553   | 0.2532   | 0.2593   | 0.018    | 0.5414   | 0.3878   |  3928   
20230905:00:03:55    67    | [0.01843 | 0.6673   | 0.483    | 0.209    | 0.2282   | 0.01226  | 0.5074   | 0.3555   |  81.1    | 0.6858   | 0.4582   | 0.2523   | 0.2545   | 0.0163   | 0.544    | 0.3865   |  3936   
20230905:00:14:18    68    | [0.01809 | 0.6698   | 0.4805   | 0.2152   | 0.2289   | 0.01198  | 0.5123   | 0.358    | 81.09    | 0.6549   | 0.485    | 0.2068   | 0.2491   | 0.0254   | 0.5045   | 0.3668   |  3927   
20230905:00:24:41    69    | [0.01775 | 0.667    | 0.4821   | 0.2122   | 0.2315   | 0.01282  | 0.5104   |  0.36    | 81.07    | 0.6767   | 0.4618   | 0.2353   | 0.2622   | 0.0259   | 0.5273   | 0.3822   |  3927   
20230905:00:35:05    70    | [0.01741 | 0.6712   | 0.4794   | 0.2174   | 0.2312   | 0.01248  | 0.5142   | 0.3604   |    81    | 0.6862   | 0.453    | 0.251    | 0.2715   | 0.0199   | 0.5358   | 0.397    |  3919   
20230905:00:35:05 Saving Checkpoint...
20230905:00:35:05 Done.
20230905:00:45:29 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                     71    | [0.01705 | 0.6715   | 0.4779   | 0.2194   | 0.2327   | 0.01252  | 0.5164   | 0.3631   | 80.94    | 0.677    | 0.4615   | 0.2437   | 0.2737   | 0.0241   | 0.5344   | 0.392    |  3918   
20230905:00:55:53    72    | [0.01669 | 0.6745   | 0.4779   | 0.2208   | 0.2323   | 0.01252  | 0.5163   | 0.3623   | 81.04    | 0.6811   | 0.4588   | 0.2463   | 0.2534   | 0.015    | 0.5338   | 0.3806   |  3929   
20230905:01:06:16    73    | [0.01633 | 0.6759   | 0.4749   | 0.2224   | 0.2357   | 0.01342  | 0.519    | 0.3668   | 81.01    | 0.6841   | 0.454    | 0.2558   | 0.2779   | 0.0241   | 0.5418   |   0.4    |  3929   
20230905:01:16:39    74    | [0.01596 | 0.674    | 0.4764   | 0.2232   | 0.236    | 0.01276  | 0.518    | 0.3635   | 81.04    | 0.6841   | 0.4637   | 0.2426   | 0.2459   | 0.0166   | 0.5357   | 0.3792   |  3923   
20230905:01:27:03    75    | [0.01558 | 0.6753   | 0.4749   | 0.2219   | 0.2358   | 0.01294  | 0.5179   | 0.3669   | 81.03    | 0.6872   | 0.4503   | 0.2659   | 0.2814   | 0.0229   | 0.5502   | 0.4058   |  3925   
20230905:01:37:26    76    | [0.01520 | 0.6774   | 0.475    | 0.2228   | 0.2353   | 0.01274  | 0.5182   | 0.3653   | 81.02    | 0.6934   | 0.4466   | 0.2642   | 0.2733   | 0.0217   | 0.547    |   0.4    |  3934   
20230905:01:47:49    77    | [0.01482 | 0.6826   | 0.4699   | 0.2317   | 0.2401   | 0.01266  | 0.5254   | 0.3706   | 81.02    | 0.6907   | 0.4517   | 0.2542   | 0.2623   | 0.0202   | 0.5455   | 0.3931   |  3931   
20230905:01:58:13    78    | [0.01443 | 0.6809   | 0.4701   | 0.232    | 0.2389   | 0.01394  | 0.5263   | 0.3704   | 81.04    | 0.6915   | 0.4458   | 0.2725   | 0.282    | 0.0219   | 0.5538   | 0.409    |  3922   
20230905:02:08:36    79    | [0.01404 | 0.6804   | 0.4713   | 0.2308   | 0.2391   | 0.01374  | 0.524    | 0.3712   | 81.07    | 0.6782   | 0.4549   | 0.2519   | 0.2782   | 0.0239   | 0.541    | 0.3999   |  3930   
20230905:02:18:58    80    | [0.01365 | 0.6819   | 0.4695   | 0.2291   | 0.2404   | 0.01336  | 0.525    | 0.3707   | 81.07    | 0.677    | 0.4671   | 0.2448   | 0.2483   | 0.015    | 0.5333   | 0.3787   |  3929   
20230905:02:18:58 Saving Checkpoint...
20230905:02:18:59 Done.
20230905:02:29:22 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                     81    | [0.01326 | 0.6822   | 0.4681   | 0.2344   | 0.2407   | 0.01342  | 0.528    | 0.3709   | 80.96    | 0.6929   | 0.4443   | 0.2686   | 0.2778   | 0.0206   | 0.5475   | 0.4041   |  3925   
20230905:02:39:46    82    | [0.01286 | 0.6824   | 0.4666   | 0.2366   | 0.2429   | 0.01422  | 0.529    | 0.3753   | 80.99    | 0.6803   | 0.4489   | 0.2727   | 0.2927   | 0.0256   | 0.5515   |  0.41    |  3923   
20230905:02:50:09    83    | [0.01246 | 0.6835   | 0.4662   | 0.2354   | 0.2465   | 0.0144   | 0.5281   | 0.3757   | 81.01    | 0.6751   | 0.4538   | 0.2566   | 0.2824   | 0.0264   | 0.5377   | 0.3975   |  3873   
20230905:03:00:32    84    | [0.01206 | 0.6867   | 0.4646   | 0.2375   | 0.2454   | 0.01498  | 0.5308   | 0.3764   | 81.05    | 0.6993   | 0.4431   | 0.2706   | 0.2748   | 0.0209   | 0.5563   | 0.4058   |  3927   
20230905:03:10:56    85    | [0.01166 | 0.6888   | 0.4646   | 0.2369   | 0.245    | 0.01356  | 0.5294   | 0.3749   | 81.02    | 0.6892   | 0.446    | 0.275    | 0.297    | 0.0287   | 0.5516   | 0.4151   |  3919   
20230905:03:21:19    86    | [0.01126 | 0.6857   | 0.4654   | 0.2391   | 0.244    | 0.01428  | 0.5312   | 0.3741   | 81.04    | 0.6945   | 0.4423   | 0.2739   | 0.2909   | 0.0269   | 0.5545   | 0.4151   |  3915   
20230905:03:31:43    87    | [0.01086 | 0.6917   | 0.4605   | 0.2426   | 0.2482   | 0.0146   | 0.5352   | 0.3786   | 80.94    | 0.7035   | 0.4378   | 0.2794   | 0.2822   | 0.0212   | 0.555    | 0.4113   |  3925   
20230905:03:42:07    88    | [0.01047 | 0.6918   | 0.4595   | 0.2445   | 0.2484   | 0.01364  | 0.5374   | 0.3814   | 80.99    | 0.704    | 0.4343   | 0.2851   | 0.2885   | 0.0213   | 0.5614   | 0.4181   |  3930   
20230905:03:52:30    89    | [0.01007 | 0.6916   | 0.4605   | 0.2439   | 0.2482   | 0.01528  | 0.5357   | 0.3818   | 80.96    | 0.685    | 0.4509   | 0.254    | 0.2874   | 0.0287   | 0.5414   | 0.4053   |  3927   
20230905:04:02:54    90    | [0.00968 | 0.6911   | 0.4609   | 0.2418   | 0.2497   | 0.01452  | 0.5333   |  0.38    | 81.01    | 0.6966   | 0.442    | 0.2731   | 0.2889   | 0.025    | 0.5533   | 0.4106   |  3920   
20230905:04:02:54 Saving Checkpoint...
20230905:04:02:54 Done.
20230905:04:13:18 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                     91    | [0.00928 | 0.6908   | 0.4597   | 0.2461   | 0.2506   | 0.01462  | 0.5367   | 0.3834   | 81.04    | 0.706    | 0.4336   | 0.2854   | 0.2867   | 0.0231   | 0.5663   | 0.4139   |  3924   
20230905:04:23:40    92    | [0.00889 | 0.6929   | 0.4571   | 0.2485   | 0.2528   | 0.01522  | 0.5394   | 0.3849   | 81.06    | 0.6884   | 0.443    | 0.2748   | 0.2943   | 0.0243   | 0.5532   | 0.4167   |  3911   
20230905:04:34:04    93    | [0.00851 | 0.6933   | 0.4551   | 0.2505   | 0.2552   | 0.01572  | 0.5395   | 0.3873   | 81.05    | 0.6996   | 0.4397   | 0.2735   | 0.2856   | 0.0232   | 0.5553   | 0.4098   |  3923   
20230905:04:44:27    94    | [0.00813 | 0.6984   | 0.4524   | 0.2545   | 0.2545   | 0.01614  | 0.5437   | 0.3875   | 81.03    | 0.686    | 0.4485   | 0.2674   | 0.2916   | 0.0262   | 0.5478   | 0.415    |  3918   
20230905:04:54:50    95    | [0.00775 | 0.6972   | 0.4551   | 0.2528   | 0.2522   | 0.01564  | 0.5431   | 0.3873   | 81.08    | 0.6878   | 0.4469   | 0.2708   | 0.2953   | 0.0288   | 0.5513   | 0.4128   |  3916   
20230905:05:05:13    96    | [0.00738 | 0.6953   | 0.4544   | 0.2533   | 0.2556   | 0.0161   | 0.5405   | 0.3887   | 81.08    | 0.703    | 0.4356   | 0.2888   | 0.2938   | 0.0237   | 0.5622   | 0.4221   |  3927   
20230905:05:15:36    97    | [0.00701 | 0.6993   | 0.4518   | 0.2561   | 0.2565   | 0.01538  | 0.5447   | 0.3899   |  81.1    | 0.7025   | 0.4341   | 0.2794   | 0.2899   | 0.0253   | 0.5604   | 0.4164   |  3924   
20230905:05:25:59    98    | [0.00665 | 0.6985   | 0.4521   | 0.2558   | 0.2544   | 0.01516  | 0.5432   | 0.3909   | 81.08    | 0.7014   | 0.4383   | 0.2777   | 0.2779   | 0.0217   | 0.558    | 0.4132   |  3919   
20230905:05:36:22    99    | [0.00629 | 0.6986   | 0.4536   | 0.2542   | 0.2541   | 0.01526  | 0.5419   | 0.387    | 81.08    | 0.7007   | 0.4392   | 0.2732   |  0.28    | 0.0221   | 0.5554   | 0.4097   |  3927   
20230905:05:46:45   100    | [0.00594 | 0.7018   | 0.4484   | 0.2615   | 0.259    | 0.0156   | 0.5489   | 0.3944   | 81.11    | 0.6964   | 0.4407   | 0.2797   | 0.2963   | 0.0292   | 0.5584   | 0.4167   |  3918   
20230905:05:46:45 Saving Checkpoint...
20230905:05:46:46 Done.
20230905:05:57:09 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                    101    | [0.00559 | 0.7032   | 0.4486   | 0.2588   | 0.2594   | 0.01514  | 0.5482   | 0.3928   | 81.06    | 0.7011   | 0.4326   | 0.2886   | 0.2983   | 0.0289   | 0.5636   | 0.4233   |  3929   
20230905:06:07:32   102    | [0.00526 | 0.7041   | 0.4477   | 0.2611   | 0.2595   | 0.01562  | 0.5503   | 0.3925   | 81.07    | 0.7051   |  0.43    | 0.2928   | 0.3074   | 0.0308   | 0.5665   | 0.4263   |  3922   
20230905:06:17:55   103    | [0.00493 | 0.7075   | 0.4444   | 0.2659   | 0.2625   | 0.01626  | 0.5521   | 0.3977   | 81.11    | 0.6964   | 0.4403   | 0.2835   | 0.2916   | 0.0231   | 0.5603   | 0.419    |  3923   
20230905:06:28:18   104    | [0.00461 | 0.7062   | 0.4456   | 0.2629   | 0.261    | 0.0155   | 0.5504   | 0.3939   | 81.06    | 0.7013   | 0.4356   | 0.2789   | 0.2862   | 0.0272   | 0.5615   | 0.4144   |  3937   
20230905:06:38:41   105    | [0.00429 | 0.7071   | 0.444    | 0.2668   | 0.2622   | 0.0158   | 0.5529   | 0.3992   | 81.08    | 0.7113   | 0.4266   | 0.3029   | 0.305    | 0.0276   | 0.5764   | 0.4284   |  3927   
20230905:06:49:04   106    | [0.00399 | 0.7088   | 0.4413   | 0.2724   | 0.264    | 0.01704  | 0.5591   | 0.401    | 81.07    | 0.7081   | 0.427    | 0.2957   | 0.2972   | 0.0279   | 0.5713   | 0.427    |  3915   
20230905:06:59:27   107    | [0.00369 | 0.7084   | 0.4415   | 0.2671   | 0.2659   | 0.01642  | 0.5538   | 0.4011   | 81.07    | 0.7104   | 0.4291   | 0.295    | 0.2944   | 0.0258   | 0.5672   | 0.4237   |  3932   
20230905:07:09:51   108    | [0.00341 | 0.7096   | 0.4413   | 0.2728   | 0.266    | 0.01604  | 0.5583   | 0.401    | 81.07    | 0.7132   | 0.4246   | 0.2984   | 0.3056   | 0.0271   | 0.5754   | 0.4291   |  3932   
20230905:07:20:14   109    | [0.00313 | 0.711    | 0.4409   | 0.2736   | 0.2676   | 0.0168   | 0.5597   | 0.4014   | 81.08    | 0.7013   | 0.4318   | 0.2859   | 0.2988   | 0.0271   | 0.563    | 0.4186   |  3913   
20230905:07:30:37   110    | [0.00286 | 0.7117   |  0.44    | 0.2728   | 0.2676   | 0.01624  | 0.5577   | 0.4041   | 81.11    | 0.7057   | 0.4251   | 0.3098   | 0.3071   | 0.0275   | 0.5748   | 0.4369   |  3927   
20230905:07:30:37 Saving Checkpoint...
20230905:07:30:37 Done.
20230905:07:41:00 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                    111    | [0.00261 | 0.7128   | 0.4392   | 0.2745   | 0.2672   | 0.01632  | 0.5591   | 0.4041   | 81.06    | 0.7038   | 0.4334   | 0.2888   | 0.2981   | 0.0256   | 0.5652   | 0.4215   |  3922   
20230905:07:51:23   112    | [0.00236 | 0.7143   | 0.4369   | 0.2773   | 0.2696   | 0.0173   | 0.5611   | 0.4075   | 81.05    | 0.7059   | 0.4279   | 0.2991   | 0.3019   | 0.0283   | 0.5712   | 0.4293   |  3915   
20230905:08:01:46   113    | [0.00213 | 0.7176   | 0.4356   | 0.2778   | 0.2698   | 0.0172   | 0.5618   | 0.4066   | 81.09    | 0.711    | 0.4225   | 0.3118   | 0.3078   | 0.0298   | 0.5777   | 0.437    |  3925   
20230905:08:12:09   114    | [0.00190 | 0.7168   | 0.4348   | 0.2821   | 0.2717   | 0.01696  | 0.5655   | 0.4077   | 81.07    | 0.7121   | 0.4213   | 0.3046   | 0.2976   | 0.0264   | 0.5774   | 0.4273   |  3918   
20230905:08:22:32   115    | [0.00169 | 0.715    | 0.4363   | 0.2791   | 0.2707   | 0.01746  | 0.5635   | 0.4083   | 81.06    | 0.7194   | 0.4197   | 0.3088   | 0.3051   | 0.0245   | 0.581    | 0.4333   |  3923   
20230905:08:32:55   116    | [0.00149 | 0.7184   | 0.4336   | 0.2815   | 0.2727   | 0.01742  | 0.5658   | 0.4089   | 81.06    | 0.7183   | 0.4197   | 0.3094   | 0.3056   | 0.0286   | 0.5838   | 0.4328   |  3917   
20230905:08:43:19   117    | [0.00130 | 0.7184   | 0.4325   | 0.2834   | 0.2734   | 0.01696  | 0.5676   | 0.4113   | 81.04    | 0.7134   | 0.4211   | 0.3129   | 0.3055   | 0.0273   | 0.5785   | 0.4374   |  3925   
20230905:08:53:42   118    | [0.00112 |  0.72    | 0.4321   | 0.2846   | 0.2732   | 0.0167   | 0.5667   | 0.4127   | 81.11    | 0.7148   | 0.4222   | 0.3056   | 0.3011   | 0.0269   | 0.579    | 0.4312   |  3932   
20230905:09:04:05   119    | [0.00096 | 0.722    | 0.4309   | 0.2873   | 0.2712   | 0.01668  | 0.5706   | 0.4127   | 81.07    | 0.7185   | 0.4203   | 0.3103   | 0.3109   | 0.0281   | 0.5815   | 0.4376   |  3919   
20230905:09:14:27   120    | [0.00081 | 0.7213   | 0.4315   | 0.2825   | 0.272    | 0.01704  | 0.5676   | 0.4105   | 81.09    | 0.7198   | 0.4198   | 0.3011   | 0.3029   | 0.0259   | 0.5771   | 0.4283   |  3916   
20230905:09:14:27 Saving Checkpoint...
20230905:09:14:28 Done.
20230905:09:24:51 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                    121    | [0.00067 | 0.7218   | 0.4297   | 0.2892   | 0.2742   | 0.01724  | 0.5719   | 0.4133   | 81.08    | 0.7183   | 0.4182   | 0.306    | 0.3055   | 0.0271   | 0.5819   | 0.4343   |  3925   
20230905:09:35:13   122    | [0.00054 | 0.7231   | 0.4298   | 0.2867   | 0.2754   | 0.01606  | 0.5694   | 0.4129   | 81.13    | 0.7181   | 0.4179   | 0.3117   | 0.3058   | 0.0263   | 0.5827   | 0.4375   |  3923   
20230905:09:45:36   123    | [0.00043 | 0.7237   | 0.4297   | 0.2881   | 0.2734   | 0.01648  | 0.5717   | 0.414    | 81.08    | 0.7179   | 0.4182   | 0.3085   | 0.3072   | 0.0278   | 0.5818   | 0.4339   |  3924   
20230905:09:55:59   124    | [0.00033 | 0.725    | 0.4295   | 0.2888   | 0.2762   | 0.0171   | 0.5697   | 0.4131   | 81.07    | 0.7187   | 0.4173   | 0.3084   | 0.3089   | 0.0266   | 0.5841   | 0.4335   |  3927   
20230905:10:06:22   125    | [0.00024 | 0.7238   | 0.4292   | 0.2889   | 0.2745   | 0.0169   | 0.5715   | 0.4123   |  81.1    | 0.7187   | 0.4169   | 0.3092   | 0.3066   | 0.0271   | 0.5855   | 0.4339   |  3925   
20230905:10:16:44   126    | [0.00016 | 0.7247   | 0.4279   | 0.2896   | 0.2763   | 0.01662  | 0.572    | 0.4144   |  81.1    | 0.7192   | 0.4169   | 0.3128   | 0.3082   | 0.0277   | 0.5857   | 0.4348   |  3924   
20230905:10:27:07   127    | [0.00010 | 0.7272   | 0.4273   | 0.2895   | 0.2728   | 0.01734  | 0.5726   | 0.4136   | 81.12    | 0.7175   | 0.4165   | 0.3166   | 0.3108   | 0.0279   | 0.5852   | 0.4367   |  3938   
20230905:10:37:30   128    | [6.11480 | 0.7243   | 0.4279   | 0.2902   | 0.2772   | 0.0167   | 0.5717   | 0.4138   | 81.13    | 0.7193   | 0.4169   | 0.3103   | 0.3081   | 0.0286   | 0.585    | 0.4373   |  3882   
20230905:10:47:52   129    | [2.72421 | 0.7255   | 0.4276   | 0.2935   | 0.2763   | 0.0173   | 0.574    | 0.415    | 81.11    | 0.7205   | 0.4163   | 0.3158   | 0.3103   | 0.0275   | 0.5861   | 0.4362   |  3903   
20230905:10:58:15   130    | [6.88298 | 0.7256   | 0.4265   | 0.2934   | 0.2771   | 0.01678  | 0.5744   | 0.417    |  81.1    | 0.7195   | 0.4163   | 0.3146   | 0.3101   | 0.0274   | 0.5864   | 0.4363   |  3932   
20230905:10:58:15 Saving Checkpoint...
20230905:10:58:16 Done.
20230905:11:08:39 Epoch:   | Learning | TrAccura | TrLoss:  | TrMargin | TrRobsta | TrRobsta | TrRobsta | TrRobsta | TrThroug | VlAccura | VlLoss:  | VlMargin | VlRobsta | VlRobsta | VlRobsta | VlRobsta | VlThroug
                    131    | [9.39754 | 0.7253   | 0.4265   | 0.292    | 0.2751   | 0.0168   | 0.5743   | 0.4147   | 81.07    | 0.7196   | 0.4164   | 0.3146   | 0.3094   | 0.0275   | 0.5868   | 0.4373   |  3924   
20230905:11:19:01   132    | [6.88298 | 0.7254   | 0.427    | 0.2902   | 0.2756   | 0.01674  | 0.5737   | 0.4151   |  81.1    | 0.7198   | 0.4164   | 0.3147   | 0.3094   | 0.0275   | 0.5868   | 0.4373   |  3920   
20230905:11:19:01 Saving Checkpoint...
20230905:11:19:02 Done.
20230905:11:19:04 Lipschitz constant: 0.9984525442123413
